# Mission-to-Mars
Use web scraping techniques to gather data from a website

## Overview
In this challenge, I used a combination of Splinter, BeautifulSoup and Selenium to automatically scrape HTML data from a website and scrape certain elements. In this case I scraped article titles and their summaries from a Mars News website and extracted temperature data from a Mars Temperature Data website. 

## Results
With the first deliverable I was able to scrape all the news article titles along with their summaries from the Mars News website using BeautifulSoup and Splinter to automate that process. 
Here is a preview of the result after extracting the HTML data:

![Capture](https://user-images.githubusercontent.com/112291075/204447409-f1bce3fb-dcbd-41a7-8c8e-9e0264906b0d.PNG)

For the second deliverable I also used BeautifulSoup, Splinter, Pandas and Numpy to extract HTML data once more and create bar charts for easier visualizations of certain questions. After scraping data into a pandas data frame I was able to provide the following info: 

The number of months in Mars: 

![months](https://user-images.githubusercontent.com/112291075/204448211-841ffa94-395a-4c73-8b4e-a4a41fd839c3.PNG)

The coldest and warmest months in Mars:

![temps](https://user-images.githubusercontent.com/112291075/204448332-392fe1b8-c62b-42f8-9ea4-c67494a2cdc3.PNG)

The months with the lowest and highest atmospheric pressure:

![pressure](https://user-images.githubusercontent.com/112291075/204448466-43db3f2f-f645-4c36-9794-69dcdb742a9a.PNG)

## Summary
Using the new methods provided by BeautifulSoup, Selenium and Splinter I am able to gather specific information in websites. With that info. I can then create visualizations with Numpy and Pandas methods to present it to an audience. 
